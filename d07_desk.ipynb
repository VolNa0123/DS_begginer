{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"d07_desk.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Задание 1 \n","\n","Напишите функцию, которая принимает на вход любой текст в виде строки и применяет к нему метод n-грамм, n передаётся в параметрах функции и является целым числом. На выходе должен быть список с n-граммами."],"metadata":{"id":"PO1YuAc190mo"}},{"cell_type":"code","source":["# Функция, которая принимает на вход любой текст в виде строки и применяет к нему метод n-грамм\n","\n","from nltk.util import ngrams, bigrams\n","import re \n","\n","def ft_ngrams(str, n):\n","  if str.find(' ') != -1:\n","    str = re.findall(r'(?i)[а-я]+', str) # Разобьем строку на слова с помощью re.findall\n","    return(list(ngrams(str, n)))# Применим метод ngrams\n","  else:\n","    return []\n","\n","print(ft_ngrams('Если программа не выдает ошибку, значит, библиотека установлена успешно.', 3))"],"metadata":{"id":"0ietnoJD7CSg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"695cbe25-efbc-4613-87ef-d45451cde6a7","executionInfo":{"status":"ok","timestamp":1650120760679,"user_tz":-180,"elapsed":287,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[('Если', 'программа', 'не'), ('программа', 'не', 'выдает'), ('не', 'выдает', 'ошибку'), ('выдает', 'ошибку', 'значит'), ('ошибку', 'значит', 'библиотека'), ('значит', 'библиотека', 'установлена'), ('библиотека', 'установлена', 'успешно')]\n"]}]},{"cell_type":"code","source":["def set_ngrams(str, n):\n","  from nltk.util import ngrams, bigrams\n","  import re \n","  str = re.findall(r'(?i)[а-я]+', str) # Разобьем строку на слова с помощью re.findall\n","  return(set(ngrams(str, n)))# Применим метод ngrams\n","\n","print(set_ngrams('Если программа не выдает ошибку, значит, библиотека установлена успешно.', 3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r1NwvccfPSgu","outputId":"261d3cd1-916f-4eb3-defb-41f7e701e42e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{('Если', 'программа', 'не'), ('значит', 'библиотека', 'установлена'), ('библиотека', 'установлена', 'успешно'), ('выдает', 'ошибку', 'значит'), ('ошибку', 'значит', 'библиотека'), ('не', 'выдает', 'ошибку'), ('программа', 'не', 'выдает')}\n"]}]},{"cell_type":"markdown","source":["# Задание 2"],"metadata":{"id":"jByjFx7ANV1E"}},{"cell_type":"markdown","source":["Напишите функцию для вычисления BLEU-score. На вход принимается две строки: перевод, предложенный алгоритмом, и референсный перевод. При подсчете метрики учитывайте n-граммы с n ∈ [1,2,3].\n","\n","Перевод, предложенный алгоритмом: \"Кошка вышла из дома и села на крыльцо\"\n","\n","Референсный перевод (ground truth): \"Кошка вышла из комнаты и села на ступеньки\"\n","\n","На выходе должен быть ответ в виде процентов, округлённый до целых."],"metadata":{"id":"kIj-AEEqOGZy"}},{"cell_type":"code","source":["# Функция для вычисления BLEUscore \"ручной\" вариант через сравнение сетов.\n","\n","def Blue3(reference, hypothesis):\n","  n = len(list(reference.split()))\n","  brevity_penalty = min(1, len(list(hypothesis.split()))/len(list(reference.split())))\n","  setr1 = set_ngrams(reference, 1)\n","  seth1 = set_ngrams(hypothesis, 1)\n","\n","  presigion1 = len(setr1 & seth1) / n\n","  setr2 = set_ngrams(reference, 2)\n","  seth2 = set_ngrams(hypothesis, 2)\n","  presigion2 = len(setr2 & seth2) / (n - 1)\n","  setr3 = set_ngrams(reference, 3)\n","  seth3 = set_ngrams(hypothesis, 3)\n","\n","  presigion3 = len(setr3 & seth3) / (n - 2)\n","  return brevity_penalty * (presigion1  * presigion2 * presigion3) ** (1/3)\n","\n","print(Blue3(reference, hypothesis))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FnNBTJMFTPZm","outputId":"fa4589a9-0999-438c-d21b-73d3d243b920"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5227579585747102\n"]}]},{"cell_type":"markdown","source":["# Задание 3"],"metadata":{"id":"qP2-V_3SBpc2"}},{"cell_type":"markdown","source":["Вспомните методы векторизации из прошлых уроков и проведите аналогичную классификацию, но также применив n-граммы. Сравните результаты.\n","\n","Проведите классификацию текстов с применением n-грамм:\n","\n","\n","1.   Проведите предобработку\n","2.   Примените n-граммы с значением n = 2. Выше брать не будем, иначе расчеты могут сильно увеличиться по времени\n","3.   Проведите векторизацию с помощью Word2Vec\n","4.   Обучите на полученных данных модель градиентного бустинга\n","5.   Сравните эффективность модели, обученой ранее без применения n-грамм, с полученными моделями по показателю precision\n","\n"],"metadata":{"id":"V6y3SKa6B8FL"}},{"cell_type":"markdown","source":["## Приведем данные в необходимый для работы вид"],"metadata":{"id":"I-xni0hzVUck"}},{"cell_type":"code","source":["!pip install pymorphy2 nltk\n","import nltk\n","nltk.download(\"punkt\")\n","nltk.download(\"stopwords\")\n","from nltk.corpus import stopwords\n","russian_stopwords = stopwords.words(\"russian\")\n","russian_stopwords.sort()\n","russian_stopwords\n","from nltk.tokenize import word_tokenize\n","import pymorphy2\n","morph = pymorphy2.MorphAnalyzer()\n","import pandas as pd\n","!pip install gensim\n","from google.colab import drive\n","import os\n","\n","drive.mount(\"/content/drive/\", force_remount=True)\n"],"metadata":{"id":"ScsNaqoNnMlg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650120692790,"user_tz":-180,"elapsed":12869,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"08faedb9-9922-4d46-c439-88af33c48b3c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n","Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["# Проведем предобработку данных\n","\n","df_p = pd.read_csv(('/content/drive/MyDrive/Pyton/positive.csv'), header = None, names = ['id', 'date', 'name', 'text', 'positive', 'rep', 'rtv', 'fav', 'total_count', 'fol', 'friends', 'list_count'], sep = ';', index_col=False)\n","df_n = pd.read_csv(('/content/drive/MyDrive/Pyton/negative.csv'), header = None, names = ['id', 'date', 'name', 'text', 'positive', 'rep', 'rtv', 'fav', 'total_count', 'fol', 'friends', 'list_count'], sep = ';', index_col=False)\n","\n","df = pd.concat([df_p, df_n], axis=0) # Соединим два датафрейма\n","df.index = list(range(226834)) # Сделаем сквозную нумерецию\n","df.positive[df.positive==-1]=0 # Заменим признак негативных высказываний на 0\n","\n","df.text = df.text.str.lower() # Приведем весь текст к строчным буквам\n","df.text = df.text.str.replace(r\"[^А-Яа-я]\",\" \") # Оставим в тексте только русские слова, удалив числа, знаки препинания, специальные символы и слова написанные латиницей\n","df.text = list(map(word_tokenize, df.text)) # Разобьем тексты на слова с помощью word_tokenize\n","\n","def lemmatization(words):\n","    global morph\n","    new_s = [morph.parse(word)[0].normal_form for word in words]\n","    return new_s\n","\n","df.text = list(map(lemmatization, df.text)) # Проведем лемматизацию полученных слов\n","\n","def delete_stopword(words):\n","    global russian_stopwords\n","    new_s = [word for word in words if word not in russian_stopwords]\n","    return new_s\n","\n","df.text = list(map(delete_stopword, df.text)) # Удалим стоп-слова из наших данных\n","\n","preprocessed_df = df[[\"text\", \"positive\"]] # Оставим только текст и значение positive\n","\n","df = df.drop(df[df.text == ''].index, axis = 0) # Удалим пустые твиты\n","\n","preprocessed_df.to_excel('/content/drive/MyDrive/Pyton/preprocessed.xlsx', index=False) # Сохраним обработанные данные\n"],"metadata":{"id":"hIi58sDGKD1x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Предобработанные данные хранятся в файле preprocessed.xlsx и теперь при перезагрузке будем сразу испорльзовать его\n","\n","df_p = pd.read_excel('/content/drive/MyDrive/Pyton/preprocessed.xlsx')\n","df_p"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"I3iHDD3W3A_q","executionInfo":{"status":"ok","timestamp":1650120747045,"user_tz":-180,"elapsed":17496,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"b59df51b-ecc6-4bec-fac9-ac7b63b07944"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                     text  positive\n","0       ['школотый', 'поверь', 'самый', 'общество', 'п...         1\n","1       ['всё', 'таки', 'немного', 'похожий', 'мальчик...         1\n","2                               ['идиотка', 'испугаться']         1\n","3       ['угол', 'сидеть', 'погибать', 'голод', 'ещ', ...         1\n","4       ['значит', 'страшилка', 'блин', 'посмотреть', ...         1\n","...                                                   ...       ...\n","226829                 ['каждый', 'хотеть', 'исправлять']         0\n","226830  ['скучать', 'вправлять', 'мозг', 'всё', 'равно...         0\n","226831                  ['школа', 'говно', 'это', 'идти']         0\n","226832                   ['тауриэль', 'грусть', 'обнять']         0\n","226833  ['такси', 'везти', 'работа', 'раздумывать', 'п...         0\n","\n","[226834 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-16c5106b-89c8-4455-8f04-b021fbd093ac\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>positive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['школотый', 'поверь', 'самый', 'общество', 'п...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>['всё', 'таки', 'немного', 'похожий', 'мальчик...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>['идиотка', 'испугаться']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>['угол', 'сидеть', 'погибать', 'голод', 'ещ', ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>['значит', 'страшилка', 'блин', 'посмотреть', ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>226829</th>\n","      <td>['каждый', 'хотеть', 'исправлять']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>226830</th>\n","      <td>['скучать', 'вправлять', 'мозг', 'всё', 'равно...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>226831</th>\n","      <td>['школа', 'говно', 'это', 'идти']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>226832</th>\n","      <td>['тауриэль', 'грусть', 'обнять']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>226833</th>\n","      <td>['такси', 'везти', 'работа', 'раздумывать', 'п...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>226834 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16c5106b-89c8-4455-8f04-b021fbd093ac')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-16c5106b-89c8-4455-8f04-b021fbd093ac button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-16c5106b-89c8-4455-8f04-b021fbd093ac');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Напишем функцию, которая из строки, которая выглядят, как список строк делает строку\n","# \"['word', 'word', ... 'word']\" -> \"word word word\"\n","\n","def ft_str(str1):\n","  return str1.replace(\"', '\", \" \")[2 : -2]"],"metadata":{"id":"rgVOJNa4pDdo","executionInfo":{"status":"ok","timestamp":1650120747046,"user_tz":-180,"elapsed":6,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["text_2_gramms = list(ft_ngrams(elem, 2) for elem in list(map(ft_str, list(df_p.text))))"],"metadata":{"id":"JK8kojnJbLuQ","executionInfo":{"status":"ok","timestamp":1650120768703,"user_tz":-180,"elapsed":2858,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["word_from_2_gramm = list(list('_'.join(j) for j in i) for i in text_2_gramms)"],"metadata":{"id":"D6EoW_i_95VM","executionInfo":{"status":"ok","timestamp":1650120769837,"user_tz":-180,"elapsed":1142,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["df_p['gramm'] = word_from_2_gramm"],"metadata":{"id":"DKYaP02-NE_d","executionInfo":{"status":"ok","timestamp":1650120769838,"user_tz":-180,"elapsed":3,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from gensim.models import Word2Vec"],"metadata":{"id":"TV36qoB13d1o","executionInfo":{"status":"ok","timestamp":1650120848181,"user_tz":-180,"elapsed":1079,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Используем gensim.models.phrasesмодуль, который позволяет автоматически определять фразы длиннее одного слова, используя статистику словосочетаний.\n","# Используя фразы, можно создать модель word2vec, где «слова» на самом деле представляют собой многословные выражения, такие как new_york_times\n","\n","from gensim.models import Word2Vec\n","from gensim.models import Phrases\n","\n","bigram_transformer = Phrases(word_from_2_gramm) # Обучим детектор биграмм\n","\n","w2v = Word2Vec(bigram_transformer[word_from_2_gramm], min_count=1) # Применим обученный детектор к корпусу"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nr_ICN8dAdcN","executionInfo":{"status":"ok","timestamp":1650107049457,"user_tz":-180,"elapsed":232083,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"f9edc289-3262-45cb-e800-463b991ad14d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n","  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"]}]},{"cell_type":"code","source":["w2v2 = Word2Vec(size=50, min_count=1) \n","w2v2.build_vocab(df_p.gramm)\n","w2v2.train(df_p.gramm, total_examples=w2v2.corpus_count, epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OsZk_iMKnlW9","executionInfo":{"status":"ok","timestamp":1650121137593,"user_tz":-180,"elapsed":251112,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"24082d87-a3e2-4150-a0ad-9a9625fd034f"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12615590, 12615590)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["w2v2.wv.get_vector(word_from_2_gramm[1][1])"],"metadata":{"id":"9euKLFl4nCCF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650121537303,"user_tz":-180,"elapsed":8,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"01b699e9-939b-4bf9-db47-63971994a3d3"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.00413261,  0.01028042,  0.00273439, -0.00789322, -0.00611603,\n","       -0.01185608, -0.01721266,  0.00502513, -0.00033006,  0.01789803,\n","       -0.01035487, -0.01678614,  0.00855789,  0.00906763,  0.00478457,\n","       -0.02443067, -0.02700089,  0.01390506,  0.00644793,  0.00762786,\n","       -0.00080804,  0.00670501, -0.02096955, -0.01987435,  0.012967  ,\n","       -0.02114706, -0.01740248, -0.0032913 ,  0.00528294, -0.02020793,\n","        0.00461137,  0.01016803,  0.00242924,  0.01326174,  0.01903724,\n","       -0.0057761 , -0.00413389, -0.00279777,  0.00125301, -0.0236604 ,\n","       -0.01311484, -0.00691408, -0.0034867 ,  0.00790981,  0.00138631,\n","        0.00167093, -0.00105271,  0.02357635,  0.02987436, -0.01530246],\n","      dtype=float32)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"wKNAXJVg7UyB","executionInfo":{"status":"ok","timestamp":1650121888261,"user_tz":-180,"elapsed":309,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["df_p['vector'] = list(np.mean(np.array(list(w2v2.wv.get_vector(j) for j in i)), axis = 0) for i in df_p.gramm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlQE8G_U5sUw","executionInfo":{"status":"ok","timestamp":1650122790733,"user_tz":-180,"elapsed":7368,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"f7a42841-cd7b-4f42-acaa-76e531e1467e"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","!pip install xgboost"],"metadata":{"id":"KmBcropJENBj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650122797651,"user_tz":-180,"elapsed":3594,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"77a9e6e3-bde4-43a2-cdc1-3788960e0d0a"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.5)\n"]}]},{"cell_type":"code","source":["# Разобьем набор текстов на тренировочную и тестовую выборки\n","\n","X_train, X_test, y_train, y_test = train_test_split(df_p.vector, df_p.positive, test_size=0.2, random_state=21)"],"metadata":{"id":"QyUping9EA5a","executionInfo":{"status":"ok","timestamp":1650122800537,"user_tz":-180,"elapsed":417,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["X_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VrCSBdWn_BaA","executionInfo":{"status":"ok","timestamp":1650122834847,"user_tz":-180,"elapsed":288,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"9983869d-be19-442c-f223-9edc14bf1da1"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["114468    [-0.0014178, 0.00064833276, -0.0030441196, -0....\n","115015    [0.004725149, 0.0016996386, 0.0028317787, 0.00...\n","147222    [0.0018055621, 0.0021858667, -0.00021114372, -...\n","119060    [-0.0036846779, 0.0038996239, -0.0028481625, -...\n","74753     [-0.00576382, -0.0021149558, 0.0013430191, -0....\n","                                ...                        \n","81968     [-0.0019464877, 0.001380681, 0.004837542, -0.0...\n","140036    [-0.0033055625, 0.0012560157, 0.00046255664, -...\n","202552    [0.0030125116, -0.0035103569, -0.0008713889, -...\n","70863     [0.0034997219, 0.0021405788, -0.0011958218, -0...\n","80841     [0.0015324403, -0.0010657313, 0.00036654848, 0...\n","Name: vector, Length: 181467, dtype: object"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWOCLkv8_uVY","executionInfo":{"status":"ok","timestamp":1650123189590,"user_tz":-180,"elapsed":294,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"9ade99e1-5348-47aa-cb9d-fa33200fc2a5"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(181467,)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsCZSTXo_ag3","executionInfo":{"status":"ok","timestamp":1650123042875,"user_tz":-180,"elapsed":326,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"b80c634a-23e7-4063-eff4-ac0fab81d7c0"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(226834, 94864)"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# Применим модель xgboost. Основные гиперпараметры: max_depth - максимальная глубина деревьев модели и n_estimators - количество деревьев.\n","# min_count=2, epochs=20\n","\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report\n","\n","xgb = XGBClassifier(max_depth=10, n_estimators=50)\n","xgb.fit(X_train, y_train)\n","y_pred = xgb.predict(X_test)\n","print(classification_report(y_pred, y_test))"],"metadata":{"id":"XGUAXAypAdVt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"6al_4WhqP-A2"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"ze2lGnAlQCnM"}},{"cell_type":"markdown","source":["---\n"],"metadata":{"id":"CM3dfCb09g1B"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"0i1s-QZD9lC_"}},{"cell_type":"code","source":["import re\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import pymorphy2\n","\n","\n","morph = pymorphy2.MorphAnalyzer()\n","\n","\n","def text_preprocessing(text):\n","    \"\"\"Функция принимает строку и возвращает список слов в начальной форме\"\"\"\n","    text = text.lower()                                                         # приводим текст к нижнему регистру\n","    text = re.sub(r\"[^А-Яа-я]\", \" \", text)                                      # удаляем все некириллические символы\n","    words = word_tokenize(text)                                                 # разбиваем тексты на списки слов\n","    words = [morph.parse(word)[0].normal_form for word in words]                # приводим слова к начальной форме\n","    words = [word for word in words if word not in stopwords.words(\"russian\")]  # удаляем слова из стоп-листа\n","    return words"],"metadata":{"id":"PzGI2ROR042S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = 'Средства у нас есть, у нас ума не хватает'\n","prep_text = text_preprocessing(text)\n","print(prep_text)\n","print(type(prep_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mk294OCY3Dgx","executionInfo":{"status":"ok","timestamp":1650104780513,"user_tz":-180,"elapsed":13,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"bf6522c4-720a-40f4-a79f-285be647ffec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['средство', 'ум', 'хватать']\n","<class 'list'>\n"]}]},{"cell_type":"code","source":["def text_to_2_gramms(text):\n","  text = ft_str(text)\n","  return ft_ngrams(text, 2)"],"metadata":{"id":"Dz1SJmpK3lpf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grammed_text = text_to_2_gramms(' '.join(prep_text))\n","grammed_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4m8qndV3dDy","executionInfo":{"status":"ok","timestamp":1650104820338,"user_tz":-180,"elapsed":277,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"dcd5d297-d0a7-4149-b0ff-8f9d6c47235c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('едство', 'ум'), ('ум', 'хвата')]"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["vectorized_grammed_text = word2vec(grammed_text)"],"metadata":{"id":"EOl86Ep_76Ra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# проверка задания 3\n","\n","text = 'Средства у нас есть, у нас ума не хватает'\n","prep_text = text_preprocessing(text)  # содержимое этой переменной сравнить с чек-листом\n","grammed_text = text_to_2_gramms(prep_text) # содержимое этой переменной сравнить с чек-листом\n","\n","vectorized_grammed_text = word2vec(grammed_text)  # содержимое этой переменной сравнить с чек-листом -> набор чисел (вектор)\n","model_score = grad_boost(vectorized_grammed_text) # содержимое этой переменной сравнить с чек-листом -> precision, число от 0 до 1"],"metadata":{"id":"JBJv1YQn3vB7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Метод LDA (Latent Dirichlet Allocation - Латентное размещение Дирихле) и тематическое моделирование"],"metadata":{"id":"Acb5F4Bkd8Bo"}},{"cell_type":"markdown","source":["LDA - один из методов тематического моделирования, позволяющий решить задачу классификации или кластеризации, где каждый класс или кластер содержит в себе тексты со схожими темами.\n","\n","По сути тематическое моделирование - это такая мягкая кластеризация на текстах (хотя этот метод может быть расширен на данные любой природы, не только текстовые). Тематическая модель позволяет отнести текст к одной или нескольким темам с некторой вероятностью. Каждая тема, в свою очередь, характеризуются наиболее вероятными для неё словами.\n","\n","К достоинствам можно отнести то, что это обучение без учителя, т.е. для обучения нам не требуются размеченные данные. \n","\n","Это же является и недостатком - тематическую модель довольно сложно настраивать, ведь нет чёткого представления чего мы хотим.\n","\n","Для того, чтобы применять к датасету текстов LDA, необходимо преобразовать корпус в term-document matrix (Терм-документная матрица).\n","\n","Терм-документная матрица — это матрица которая имеер размер $N \\times W$, где\n","N — количество документов в корпусе, а W — размер словаря корпуса т.е. количество уникальных слов, которые встречаются в нашем корпусе. В i-й строке, j-м столбце матрицы находится число — сколько раз в i-м тексте встретилось j-е слово."],"metadata":{"id":"W_2QzzbqgJov"}},{"cell_type":"markdown","source":["# Задание 4"],"metadata":{"id":"kvhKuMKBO7Ii"}},{"cell_type":"markdown","source":["Используя модель LDA, кластеризуйте твиты на положительные и негативные. Для этого:\n","1. Проведите предобработку данных\n","2. Представьте корпус твитов в виде Терм-документной матрицы (CountVectorizer), не забудьте о стоп-словах\n","3. Поэксперементируйте с параметром `max-iter` модели, подберите лучший вариант. [Документация](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)\n","4. В качестве оценки используйте степень правдоподобия (Log-likehood). Сделайте сравнительный анализ степеней правдоподобия, соответсвующих каждому рассмотренному набору параметров (например, в виде графиков зависимости степени правдоподобия от конкретного параметра)."],"metadata":{"id":"bEi_Iw-2O_tu"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"fEowTxCPzQ5Z","executionInfo":{"status":"ok","timestamp":1650119896814,"user_tz":-180,"elapsed":711,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Предобработанные данные хранятся в файле preprocessed.xlsx и теперь при перезагрузке будем сразу испорльзовать его\n","\n","df_p = pd.read_excel('/content/drive/MyDrive/Pyton/preprocessed.xlsx')\n","df_p"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"pAD1k7TOXOGC","outputId":"b4b3e598-efab-4d9d-ecfe-b429d8755b04","executionInfo":{"status":"ok","timestamp":1650119920059,"user_tz":-180,"elapsed":22972,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                     text  positive\n","0       ['школотый', 'поверь', 'самый', 'общество', 'п...         1\n","1       ['всё', 'таки', 'немного', 'похожий', 'мальчик...         1\n","2                               ['идиотка', 'испугаться']         1\n","3       ['угол', 'сидеть', 'погибать', 'голод', 'ещ', ...         1\n","4       ['значит', 'страшилка', 'блин', 'посмотреть', ...         1\n","...                                                   ...       ...\n","226829                 ['каждый', 'хотеть', 'исправлять']         0\n","226830  ['скучать', 'вправлять', 'мозг', 'всё', 'равно...         0\n","226831                  ['школа', 'говно', 'это', 'идти']         0\n","226832                   ['тауриэль', 'грусть', 'обнять']         0\n","226833  ['такси', 'везти', 'работа', 'раздумывать', 'п...         0\n","\n","[226834 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-cdedb2a1-f13f-4151-b9db-4b1e0ed36bf9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>positive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['школотый', 'поверь', 'самый', 'общество', 'п...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>['всё', 'таки', 'немного', 'похожий', 'мальчик...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>['идиотка', 'испугаться']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>['угол', 'сидеть', 'погибать', 'голод', 'ещ', ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>['значит', 'страшилка', 'блин', 'посмотреть', ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>226829</th>\n","      <td>['каждый', 'хотеть', 'исправлять']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>226830</th>\n","      <td>['скучать', 'вправлять', 'мозг', 'всё', 'равно...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>226831</th>\n","      <td>['школа', 'говно', 'это', 'идти']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>226832</th>\n","      <td>['тауриэль', 'грусть', 'обнять']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>226833</th>\n","      <td>['такси', 'везти', 'работа', 'раздумывать', 'п...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>226834 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdedb2a1-f13f-4151-b9db-4b1e0ed36bf9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cdedb2a1-f13f-4151-b9db-4b1e0ed36bf9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cdedb2a1-f13f-4151-b9db-4b1e0ed36bf9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","import pymorphy2\n","\n","\n","morph = pymorphy2.MorphAnalyzer()\n","corpus = df_p.text\n","\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(corpus)\n","vectorizer.get_feature_names_out()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wv3If5SWLTQp","outputId":"12ce4b02-1990-4371-cf4e-b213347641f2","executionInfo":{"status":"ok","timestamp":1650119923060,"user_tz":-180,"elapsed":3013,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['аа', 'ааа', 'аааа', ..., 'ёрса', 'ёрш', 'ёршик'], dtype=object)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Терм-документная матрица\n","pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())"],"metadata":{"id":"bTNHxqvOl8JD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.decomposition import LatentDirichletAllocation\n","\n","lda = LatentDirichletAllocation(n_components=2, max_iter=10)\n","lda.fit(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVq2uKA6DKHl","outputId":"07813a51-cf42-4cef-ade5-db29ced97fa1","executionInfo":{"status":"ok","timestamp":1650120402368,"user_tz":-180,"elapsed":479319,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LatentDirichletAllocation(n_components=2)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["lda.score(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JelPhUi74FYo","executionInfo":{"status":"ok","timestamp":1650121195627,"user_tz":-180,"elapsed":33544,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"634a2ca4-744d-4a01-c669-6ca40a16b3e4"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-12801002.056882793"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["lda2 = LatentDirichletAllocation(n_components=2, max_iter=2)\n","lda2.fit(X)\n","lda2.score(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1uLJNoKM4Y_R","executionInfo":{"status":"ok","timestamp":1650121536358,"user_tz":-180,"elapsed":328915,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"5e8eed85-5a31-4a45-d8ef-8d0976baeb10"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-12872769.791511888"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["lda20 = LatentDirichletAllocation(n_components=2, max_iter=20)\n","lda20.fit(X)\n","lda20.score(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CzEOzkp85A3p","executionInfo":{"status":"ok","timestamp":1650122778997,"user_tz":-180,"elapsed":830847,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"2a31d50b-f594-46fc-d590-1dcad8bbd61f"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-12759794.873599421"]},"metadata":{},"execution_count":23}]}]}