{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"d08_desk.ipynb","provenance":[{"file_id":"1UFjINUyrdyAjkBgCXCVlDE1gtYHZu1yK","timestamp":1650185616212}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qF61u6m-8j4V","outputId":"098f2849-b36b-491f-dd63-45aa0a89b4db","executionInfo":{"status":"ok","timestamp":1650282959716,"user_tz":-180,"elapsed":2704,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"]}],"source":["!pip install keras"]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"id":"HbTTdK3YENwO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","tf.config.list_physical_devices('GPU') #  команда покажет название видеокарты, подходящей для использования при обучении нейронок"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HDbqgx-kEQ6h","outputId":"5d0f5fc2-0601-47f5-cd9e-88b6e7b6a9ae","executionInfo":{"status":"ok","timestamp":1650282970202,"user_tz":-180,"elapsed":3628,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import tensorflow as tf\n","tf.test.gpu_device_name() # Уточним, используется ли сейас графический процессор"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"r7CVqAv8XC35","outputId":"7edeae3d-380f-45d4-afce-4f978b6a2cd2","executionInfo":{"status":"ok","timestamp":1650282971786,"user_tz":-180,"elapsed":324,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["''"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import numpy as np\n","np.random.seed(123)  # для воспроизводимости\n","from keras.models import Sequential                           # Sequential - это базовый класс нейронки в керасе\n","from keras.layers import Dense, Dropout, Activation, Flatten  # дальше импортируем классы слоев\n","from keras.layers import Convolution2D, MaxPooling2D          # еще немного слоев, которые предназначены именно для работы с картинками\n","from keras.utils import np_utils\n","from keras.datasets import mnist                              # а это - классический набор картинок с рукописными цифрами, которые мы будем\n","                                                              # классифицировать в нашем примере"],"metadata":{"id":"9Lyo0X7ZEPfC","executionInfo":{"status":"ok","timestamp":1650277681613,"user_tz":-180,"elapsed":322,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# загрузим архив с фотографиями во временную папку /tmp/ и назовем его dataset.zip\n","\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n","    -O /tmp/dataset.zip"],"metadata":{"id":"kPFmby3L41Xy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shutil\n","import zipfile\n","\n","local_zip = '/tmp/dataset.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall(\"/tmp/dataset\")\n","!mkdir dataset\n","!mv /tmp/dataset/cats_and_dogs_filtered/train/* dataset/\n","!mv /tmp/dataset/cats_and_dogs_filtered/validation/cats/* dataset/cats/\n","!mv /tmp/dataset/cats_and_dogs_filtered/validation/dogs/* dataset/dogs/\n","!rm -rf /tmp/dataset\n","!rm -rf /tmp/dataset.zip"],"metadata":{"id":"ho7uquYi5FNn","executionInfo":{"status":"ok","timestamp":1650277696091,"user_tz":-180,"elapsed":2677,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import os"],"metadata":{"id":"VjeaYEBk_pP_","executionInfo":{"status":"ok","timestamp":1650277696980,"user_tz":-180,"elapsed":4,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Функция, которая перераспределяет файлы по выборкам\n","\n","def train_test_split_images(str):\n","  # Создадим нужные папки\n","  level_1 = str + '/animals'\n","  os.mkdir(level_1)\n","  level_2_1 = level_1 + '/test'\n","  level_2_2 = level_1 + '/train'\n","  os.mkdir(level_2_1)\n","  os.mkdir(level_2_2)\n","  level_3_1 = level_2_1 + '/cats'\n","  level_3_2 = level_2_1 + '/dogs'\n","  level_3_3 = level_2_2 + '/cats'\n","  level_3_4 = level_2_2 + '/dogs'\n","  os.mkdir(level_3_1)\n","  os.mkdir(level_3_2)\n","  os.mkdir(level_3_3)\n","  os.mkdir(level_3_4)\n","\n","# Распределим файлы\n","  len1 = len(os.listdir('./dataset/cats'))\n","  for n in range(0, len1):\n","    if n % 5 == 0:\n","      path = './dataset/animals/test/cats'\n","    else:\n","      path = './dataset/animals/train/cats'\n","    file = './dataset/cats/' + os.listdir('./dataset/cats')[0]\n","    shutil.move(file , path)\n","\n","  len2 = len(os.listdir('./dataset/dogs'))\n","  for n in range(0, len2):\n","    if n % 5 == 0:\n","      path = './dataset/animals/test/dogs'\n","    else:\n","      path = './dataset/animals/train/dogs'\n","    file = './dataset/dogs/' + os.listdir('./dataset/dogs')[0]\n","    shutil.move(file , path)"],"metadata":{"id":"f-gELAo8Snx-","executionInfo":{"status":"ok","timestamp":1650277699707,"user_tz":-180,"elapsed":3,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_test_split_images('./dataset')"],"metadata":{"id":"MbDVjBCrIa3-","executionInfo":{"status":"ok","timestamp":1650277704565,"user_tz":-180,"elapsed":1676,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# shutil.rmtree(os.path.join('./dataset/animals')) # Удаление папки"],"metadata":{"id":"Ev4ItdHHN_oe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Если нужна другая выборка, то можно просто перемешать исходную\n","\n","import random\n","\n","random.shuffle(data)"],"metadata":{"id":"449GEsDn01w7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir('./dataset/animals/train')  # Посмотрим состав папки"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBaxemB2ILuf","executionInfo":{"status":"ok","timestamp":1650203314830,"user_tz":-180,"elapsed":232,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"c9dbfa65-edae-4cc0-ea8a-616207ec934c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['cats', 'dogs']"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["len(os.listdir('./dataset/animals/train/cats'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOvUQNtcZy6P","executionInfo":{"status":"ok","timestamp":1650202045381,"user_tz":-180,"elapsed":245,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"2f1d257b-2abe-4c5d-f6e7-af0a00adaa0c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1200"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["len(os.listdir('./dataset/animals/test/cats'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X83KSr0oht-N","executionInfo":{"status":"ok","timestamp":1650277708040,"user_tz":-180,"elapsed":304,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"e1324219-20a8-4fc7-94ee-d52dc950acdd"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["300"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"ih_t42rAZCUe"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"yn71j-aaZAbe"}},{"cell_type":"markdown","source":["В этой работе мы будем использовать нейросеть определенного типа - VGG19 с весами ResNet, параметры изображений для которой зададим заранее."],"metadata":{"id":"CNIk4LTEUUst"}},{"cell_type":"code","source":["import numpy as np\n","np.random.seed(123)  # для воспроизводимости\n","from keras.models import Sequential\n","from keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D, Dropout, Flatten, Activation, Dense\n","from keras.utils import np_utils\n","from keras.preprocessing.image import img_to_array\n","from keras.applications import imagenet_utils\n","from keras.preprocessing.image import ImageDataGenerator"],"metadata":{"id":"R_l0YzpOU8WV","executionInfo":{"status":"ok","timestamp":1650277713551,"user_tz":-180,"elapsed":315,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# размер для ResNet'a\n","img_width, img_height = 224, 224\n","\n","# корневая папка\n","root_dir = './dataset'  # введите сюда адрес корневой папки\n","# папка с тренировочными картинками\n","train_dir = os.path.join(root_dir, 'animals', 'train')\n","# и папка с тестовыми\n","test_dir = os.path.join(root_dir, 'animals', 'test')\n","# размер батча\n","batch_size = 16"],"metadata":{"id":"MlGaqKMhUfRY","executionInfo":{"status":"ok","timestamp":1650277716618,"user_tz":-180,"elapsed":5,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["В фотографиях, с которыми придется иметь дело нейросети, кошки и собаки могут быть абсолютно разные, сфотографированные под разными углами и с разной степенью приближения. Имея конечную тренировочную выборку, мы можем ее расширить, поворачивая и приближая имеющиеся изображения. В этом нам поможет класс [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)"],"metadata":{"id":"rnxdCmV-WqDb"}},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,  # приведем значения пикселей к 0-1\n","    shear_range=0.2,   # максимальный угол поворота изображений\n","    zoom_range=0.2,    # максимальное приближение изображений\n","    horizontal_flip=True)  # используем повороты изображений для обогащения обучающей выборки\n","\n","test_datagen = ImageDataGenerator(rescale=1. / 255)  # замер качества мы должны проводить на оригинальных изображениях, \n","                                                     # поэтому тестовую выборку мы не будем вращать и приближать"],"metadata":{"id":"iiiXr5KMXLAI","executionInfo":{"status":"ok","timestamp":1650277729916,"user_tz":-180,"elapsed":321,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["Далее считаем изображения из папки, приведя их к тому размеру, с которым работает сеть VGG19. Кстати говоря, преимущество ImageDataGenerator'а в том, что картинки, разложенные по подпапкам, автоматически считаются объектами разных классов."],"metadata":{"id":"q6EDmwh0ZJgn"}},{"cell_type":"code","source":["train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","test_generator =  test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='categorical')"],"metadata":{"id":"JyhVMmJkYC_L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650277733003,"user_tz":-180,"elapsed":456,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"ed59bcb5-dca3-486b-af92-ad526071b02a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2400 images belonging to 2 classes.\n","Found 600 images belonging to 2 classes.\n"]}]},{"cell_type":"markdown","source":["# Задание 2. Переиспользование топологий нейронных сетей\n","\n","Построим модель. Ваша задача - найти в интернете архитектуру VGG19 и описать нейросеть по этой архитектуре через keras. Рекомендую ориентироваться на архитектуру, описанную в официальном репозитории кераса на github.com. Ссылку на него здесь не приведена сознательно, поскольку большая часть работы программиста заключается в умении гуглить, и этот навык лучше тренировать сразу."],"metadata":{"id":"712LXZZFRJjI"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers.core import Flatten, Dense, Dropout\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n","import cv2, numpy as np"],"metadata":{"id":"9btjH7SHJ3HT","executionInfo":{"status":"ok","timestamp":1650277739642,"user_tz":-180,"elapsed":769,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def vlg_34():\n","    from keras import backend\n","    from keras.applications import imagenet_utils\n","    from keras.engine import training\n","    from keras.layers import VersionAwareLayers\n","    from keras.utils import data_utils\n","    layers = VersionAwareLayers()\n","    input_shape = imagenet_utils.obtain_input_shape(\n","        None,default_size=224,min_size=32,\n","        data_format=backend.image_data_format(),\n","        require_flatten=True,weights='imagenet')\n","    img_input = layers.Input(shape=input_shape)\n","    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n","    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n","    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n","    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n","    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n","    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n","    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n","    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n","    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n","    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n","    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n","    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n","    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n","    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n","    x = layers.Flatten(name='flatten')(x)\n","    x = layers.Dense(4096, activation='relu', name='fc1')(x)\n","    x = layers.Dense(4096, activation='relu', name='fc2')(x)\n","    imagenet_utils.validate_activation('softmax', 'imagenet')\n","    x = layers.Dense(1000, activation='softmax',\n","                        name='predictions')(x)\n","    model2 = training.Model(img_input, x, name='vgg19')\n","    model2.load_weights(data_utils.get_file(\n","            'vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n","            'https://storage.googleapis.com/tensorflow/keras-applications/'\n","                'vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n","            cache_subdir='models',\n","            file_hash='cbe5617147190e668d6c5d5026f83318'))\n","    return model2\n","model = Sequential()\n","model.add(vlg_34())\n","model.add(Dense(2, activation='softmax'))\n","model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])\n","model.save_weights(os.path.join(root_dir,'vgg19_weights_tf_dim_ordering_tf_kernels.h5'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UL28M5UZQS7a","executionInfo":{"status":"ok","timestamp":1650278382929,"user_tz":-180,"elapsed":7873,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"8eb108bc-1e71-4695-d446-9798eb3533c3"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n","574717952/574710816 [==============================] - 5s 0us/step\n","574726144/574710816 [==============================] - 5s 0us/step\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","inputShape = (height,width,depth)\n","        \n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x))\n","        \n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x))\n"," \n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x))\n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x))\n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x))\n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x))\n","\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x))\n","\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x))\n","\n","model.add(layers.Flatten(name='flatten')(x))\n","model.add(layers.Dense(4096, activation='relu', name='fc1')(x))\n","model.add(layers.Dense(4096, activation='relu', name='fc2')(x))\n","#model.add(layers.Dense(1000, activation='softmax', name='predictions')(x))"],"metadata":{"id":"03uDJ0fwneuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Сохраним веса модели\n","\n","#model.save_weights('./dataset/vgg19_weights_tf_dim_ordering_tf_kernels.h5')"],"metadata":{"id":"XC7whmU4LBTM","executionInfo":{"status":"ok","timestamp":1650278164914,"user_tz":-180,"elapsed":466,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Подгрузим веса модели, подобранные экспертами до нас. Если на предыдущем этапе вы создали неправильную архитектуру, следующая ячейка упадет с ошибкой."],"metadata":{"id":"4auVLytCeEdA"}},{"cell_type":"code","source":["# Загрузим веса\n","\n","model.load_weights(os.path.join(root_dir, 'vgg19_weights_tf_dim_ordering_tf_kernels.h5'))"],"metadata":{"id":"Tz39TBG4eDBd","executionInfo":{"status":"ok","timestamp":1650278416233,"user_tz":-180,"elapsed":843,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["Осталось добавить полносвязный слой из двух нейронов (по количеству наших классов) с функцией активации softmax, чтобы наша модель могла производить бинарную классификацию изображений."],"metadata":{"id":"Vxu6QQQ2fTuU"}},{"cell_type":"code","source":["# Добавим полносвязный слой из двух нейронов \n","\n","model.add(Dense(2, activation='softmax'))  # у нас стоит задача двухклассовой классификации, поэтому в выходном слое 2 нейрона"],"metadata":{"id":"5Ju2Emvka00H","executionInfo":{"status":"ok","timestamp":1650278423413,"user_tz":-180,"elapsed":521,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["Скомпилируем и обучим сеть. Поскольку данные у нас теперь будут подаваться через генераторы, обучать модель нужно не методом fit, а методом fit_generator."],"metadata":{"id":"McL0zVveg2cu"}},{"cell_type":"code","source":["model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"],"metadata":{"id":"AfxsFBcM4Hua","executionInfo":{"status":"ok","timestamp":1650278426531,"user_tz":-180,"elapsed":6,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# для примера обучим одну эпоху\n","model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=250 // batch_size,\n","    epochs=1,\n","    workers=3)"],"metadata":{"id":"tjJgKqcig4h3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650278471670,"user_tz":-180,"elapsed":42982,"user":{"displayName":"Наталья Волкова","userId":"00309068704336256241"}},"outputId":"d4eeacaa-c2ef-4d9b-98d6-414f5cb28ae5"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  \n"]},{"output_type":"stream","name":"stdout","text":["15/15 [==============================] - 24s 571ms/step - loss: 0.7053 - accuracy: 0.5250\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f82f85656d0>"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["# Задание 3. Обучение сети\n","\n","Обучите 20 эпох сети, замеряя качество после каждой эпохи. Постройте график зависимости качества классификации от количества эпох сети. На какой эпохе качество модели превысит 0.45?"],"metadata":{"id":"9oXNhkrIhUp6"}},{"cell_type":"code","source":["scores = {}\n","for n_epochs in range(1, 20): \n","    model.fit_generator(train_generator, steps_per_epoch=250 // batch_size, validation_data=test_generator, epochs=20, workers=3, vebrose=level_3_1))\n","    score = model.evaluate(train_generator, verbose=0)  # замеряем текущее качество классификации\n","    scores[n_epochs] = score  # сохраним текущее качество, чтобы построить график\n","\n","# А теперь посмотрим, как менялось качество в процессе обучения нейронки\n","plt.plot(list(scores.keys()), list(map(lambda x: x[1], scores.values())))\n","plt.xlabel(\"Количество эпох\")\n","plt.ylabel(\"Качество классификации\")\n","plt.title(\"Качество классификации цифр в зависимости от количества эпох\")\n","plt.show()"],"metadata":{"id":"RP_aFBgFQ7_0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Задание 4. Готовые архитектуры нейросетей\n","\n","В keras описаны некоторые популярные архитектуры нейросетей. При этом их можно использовать в качестве одного из слоев другой нейросети. В частности, есть готовый класс, в котором описана VGG19 с теми весами, которые мы подгружали из файла (ImageNet)."],"metadata":{"id":"HgpJCJjTgTtg"}},{"cell_type":"code","source":["from keras.applications.vgg19 import VGG19\n","\n","ready_model = Sequential()\n","ready_model.add(VGG19(weights='imagenet'))\n","ready_model.add(Dense(2, activation='softmax')) \n","ready_model.compile(optimizer='sgd', loss='categorical_crossentropy')"],"metadata":{"id":"b-VbvRuJa0xK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Изучите, какие нейросети также популярны для классификации изображений. Выберите 2 архитектуры, постройте модели с их использованием, выберите наилучшую по качеству на 20 эпохах и лучшую по скорости обучения."],"metadata":{"id":"CUGHafS6ik3m"}},{"cell_type":"code","source":["# решение задания 4"],"metadata":{"id":"s2pY_k8LjDXj"},"execution_count":null,"outputs":[]}]}